üåç DOSSIER DE CONFIGURATION D'EXPLOITATION (DCE)
# üöÇ Camrail Industrial Data Platform (End-to-End) V1.0
![Python](https://img.shields.io/badge/Python-3.12-blue) ![SQLite](https://img.shields.io/badge/SQLite-Data_Warehouse-lightgrey) ![Scikit-Learn](https://img.shields.io/badge/Scikit_Learn-Machine_Learning-orange) ![Power BI](https://img.shields.io/badge/Power_BI-Data_Visualization-yellow)

**Version:** 1.0.0 Stable | **Date:** F√©vrier 2026  
**Auteur:** KAMENI TCHOUATCHEU GAETAN BRUNEL  
**Contact:** gaetanbrunel.kamenitchouatcheu@et.esiea.fr

üöÄ [D√©marrage Rapide](#-d√©marrage-rapide) ‚Ä¢ üìö [Documentation](#-guide-dutilisation) ‚Ä¢ üéØ [Fonctionnalit√©s](#-fonctionnalit√©s-cl√©s) ‚Ä¢ üîß [Installation](#-installation-compl√®te)

---

## üìã TABLE DES MATI√àRES
1. [Vue d'ensemble du projet](#-vue-densemble-du-projet)
2. [Architecture Technique](#Ô∏è-architecture-technique)
3. [Stack Technologique](#Ô∏è-stack-technologique)
4. [Fonctionnalit√©s Cl√©s](#-fonctionnalit√©s-cl√©s)
5. [D√©marrage Rapide](#-d√©marrage-rapide)
6. [Installation Compl√®te](#-installation-compl√®te)
7. [Guide d'Utilisation](#-guide-dutilisation)
8. [Qualit√© & Best Practices](#-qualit√©--best-practices)
9. [Roadmap & √âvolutions](#Ô∏è-roadmap--√©volutions)

---

## üéØ VUE D'ENSEMBLE DU PROJET

### Contexte & Objectifs
Ce projet d√©montre la mise en ≈ìuvre d'une architecture de donn√©es de bout en bout (End-to-End) unifiant l'**Ing√©nierie de Donn√©es (ETL)** et la **Data Science (IA)**. Il s'inscrit dans le contexte critique de la logistique ferroviaire de fret (Camrail - Bollor√© Logistics √† Douala), illustrant un profil "Full-Stack Data".

‚úÖ **Data Engineering (Extraction & Chargement) :** Orchestration d'un pipeline ETL simulant des dizaines de milliers de lignes de t√©l√©m√©trie vers un SQL Data Warehouse.
‚úÖ **Data Transformation (Nettoyage) :** Feature engineering avanc√© avec Pandas (Moyennes glissantes thermiques et vibratoires des essieux).
‚úÖ **Data Science (Machine Learning) :** Algorithme de Random Forest se connectant directement au SQL pour scorer le risque de pannes des locomotives et r√©ins√©rant ses r√©sultats fermement dans la base de donn√©es.
‚úÖ **Data Visualization :** Sp√©cifications pour une connexion en "Live" de Power BI √† cette m√™me base SQlite.
‚úÖ **Automatisation IT :** Script d'orchestration global `run_industrial_platform.py` pr√™t pour un scheduler nocturne (CRON de nuit).

### Pourquoi ce projet ?
| Aspect | D√©monstration |
| :--- | :--- |
| **Gouvernance de la Donn√©e** | √âviction des fichiers plats au profit d'une Source Unique de V√©rit√© (SSOT) en SQL. |
| **Bout en Bout** | Autonomie totale de la captation physique (simul√©e) jusqu'au tableau de bord du D√©cideur. |
| **Maintenabilit√©** | Architecture hexagonale o√π ETL et Mod√©lisation Machine Learning sont cloisonn√©s en sous-dossiers distincts. |
| **Business Value** | KPI calcul√©s (Alertes pannes) imm√©diatement interpr√©tables (Passage d'une maintenance √† date fixe √† prescriptive). |

---

## üèóÔ∏è ARCHITECTURE TECHNIQUE

### Diagramme de Flux (Architecture End-to-End)

```mermaid
graph TB
    subgraph "Phase 1 : DATA ENGINEERING (ETL)"
        A[üì° Capteurs IoT Locomotives] -->|Extraction| B[üêç Nettoyage & Feature Engineering]
        B -->|SQLAlchemy : Upsert| C[(database/industrial_dwh.sqlite)]
    end
    
    subgraph "Phase 2 : DATA SCIENCE (IA)"
        C -->|1. Lecture SQL des Features| D[üß† Mod√®le: RandomForestClassifier]
        D -->|2. Entra√Ænement Historique| E[rf_failure_predict.joblib]
        D -->|3. Score de Risque| F[R√©√©criture Automatis√©e]
        F -->|Table: ai_telemetry_predictions| C
    end
    
    subgraph "Phase 3 : RESTITUTION (Power BI)"
        C -->|Connexion Live ODBC/SQLite| G[üìâ Tableau de Bord D√©cisionnel]
        G -->|Visualisation| H[√âcran Chef de Gare]
    end
    
    style C fill:#50C878,stroke:#333,stroke-width:2px,color:#000
    style D fill:#FF6B6B,stroke:#333,stroke-width:2px,color:#fff
    style G fill:#ff9,stroke:#333,stroke-width:2px,color:#000
```

### Explication du Flux

1. **Script de T√™te (`run_industrial_platform.py`) :** C'est le chef d'orchestre. Lorsqu'il est lanc√©, il ex√©cute les deux phases s√©quentiellement avec une gestion des exceptions.
2. L'extraction (**`src/data_engineering/extract.py`**) g√©n√®re 10 000 points de t√©l√©m√©trie bruts simul√©s (Pression d'huile, Temp√©rature moteur).
3. La transformation (**`src/data_engineering/transform.py`**) cr√©e les agr√©gats glissants (Rolling Means).
4. Le chargeur (**`src/data_engineering/load.py`**) ins√®re de fa√ßon transactionnelle les lignes trait√©es dans le *Data Warehouse* central (SQLite via SQLAlchemy).
5. Aussit√¥t l'ETL termin√©, l'Intelligence Artificielle (**`src/data_science/train_and_predict.py`**) se connecte en SQL (SELECT), s'entra√Æne sur l'usure des locomotives, d√©busque les pannes imminentes, et g√©n√®re et ins√®re instantan√©ment une table pr√©dictive ("Score de risque probabilit√©s = [0.1...0.99]") `ai_telemetry_predictions` dans ce m√™me Data Warehouse SQL !

---

## üõ†Ô∏è STACK TECHNOLOGIQUE

### Technologies Core
| Composant | Technologie | Version | Justification Technique |
| :--- | :--- | :--- | :--- |
| **Langage Principal** | Python | 3.12+ | L'√©cosyst√®me absolu du Data Engineer et Data Scientist |
| **Moteur SGBD SQL**| SQLite3 | - | Moteur SQL embarqu√© ultral√©ger, rempla√ßable facilement par PostgreSQL via l'engine |
| **Data Engineering** | Pandas & SQLAlchemy | 2.1+ / 2.0+ | Extraction vectoris√©e et ORM Base de Donn√©es ultra-robuste |
| **Machine Learning** | Scikit-Learn | 1.3+ | Puissance des Random Forest, hautement explicable √† l'industrie |
| **Reporting KPI** | Power BI | - | Connexion ODBC directe au DWH SQL pour rafra√Æchissement temps r√©el |
| **Tracabilit√©** | Loguru | 0.7+ | Traces asynchrones magnifiquement color√©es en console |

---

## üéØ FONCTIONNALIT√âS CL√âS

### üöÄ Fonctionnalit√©s Principales

**1. Orchestrateur Centralis√©**
* Un script ma√Ætre `run_industrial_platform.py` agit comme "Cron" process. Il pilote les d√©pendances et s√©curise le flux (arr√™te tout si l'ETL √©choue, √©vitant de faire crasher l'IA).

**2. Simulation & Feature Engineering Data**
* G√©n√©ration pointue de 10k+ lignes avec des signaux de panne bruit√©s (bruit gaussien de temp√©rature moteurs). Lissage par moyenne mobile `Rolling` dans Pandas.

**3. IA Nativement Interconnect√©e au SGBD**
* Random Forest avec ajustement du poids des classes sous-repr√©sent√©es (`class_weight='balanced'`).
* L'IA requ√™te directement sa base via SQL queries, garantissant la s√ªret√© et la fra√Æcheur ("Source of Truth").

### üõ°Ô∏è S√©curit√©, Qualit√© & Robustesse
| Aspect | Impl√©mentation |
| :--- | :--- |
| **Modularit√© Stricte** | Dossier `data_engineering` herm√©tique vis-√†-vis de `data_science`. Le lien s'op√®re par contrat de donn√©es (La Base SQL). |
| **Logs Structur√©s** | Historisation de l'ex√©cution dans `logs/platform_execution.log`. |
| **Versionning IA** | Les objets s√©rialis√©s (*mod√®le*.joblib) ont leur dossier d√©di√© et mis sur GitHub LFS. |

---

## üöÄ D√âMARRAGE RAPIDE

### Pr√©requis
```bash
# V√©rifier Python
python --version  # Doit √™tre >= 3.12
```

### Installation Express
```bash
# 1. Naviguer dans le dossier du projet
cd Camrail-Industrial-Data-Platform

# 2. Cr√©er un environnement virtuel
python -m venv env
.\env\Scripts\activate

# 3. Installer les d√©pendances
pip install -r requirements.txt

# 4. Lancer l'usine num√©rique (Orchestrateur E2E)
python run_industrial_platform.py
```
*(Une fois termin√©, regardez dans le dossier `database/`, le fichier `industrial_dwh.sqlite` contiendra toutes vos tables, donn√©es nettoy√©es, et pr√©dictions de pannes.)*

---

## üìñ GUIDE D'UTILISATION

### Analyse des R√©sultats
Une fois l'orchestrateur ex√©cut√© :
1. **Dossier `database/`** : Ouvrez `industrial_dwh.sqlite` avec un client SGBD l√©ger comme [DB Browser for SQLite] ou [DBeaver].
2. **Tables disponbiles** : Inspectez les tables "fact_telemetry_features" (vos donn√©es pures format√©es) et "ai_telemetry_predictions" (enrichies du `%_de_Risque_Panne`).
3. **Power BI** : Dans Power BI Desktop, connectez la source ODBC/SQLite sur le fichier `.sqlite` absolu.

---

## ‚ú® QUALIT√â & BEST PRACTICES

### Principes Appliqu√©s
| Principe | Impl√©mentation |
| :--- | :--- |
| **SSOT (Single Source Of Truth)** | L'unique point de passage de l'information est le Data Warehouse SQL (industrial_dwh). |
| **Separation of Concerns** | Extracteurs / Transformateurs / Chargeurs isol√©s dans des fichiers .py uniques. |
| **Data Imbalance (DS)** | Technique rigoureuse de stratification crois√©e appliqu√©e √† la scission d'apprentissage IA. |

---

## üó∫Ô∏è ROADMAP & √âVOLUTIONS

**Version Actuelle : 1.0.0** ‚úÖ
* [x] Pipeline EXTRACT, TRANSFORM, LOAD complet en m√©moire
* [x] Enrobement SGBD par SQLAlchemy Engine
* [x] R√©tro-Connexion du Machine Learning et pr√©diction par scoring SQL
* [x] Design "End-to-End" achev√© orient√© Fret Logistique

**Version 1.1.0 (Prochaine Release)** üöß
* Bascule dynamique sur un PostgreSQL Azure Cloud au lieu du ficher SQLite file-system.

---

## üë®‚Äçüíª AUTEUR
**KAMENI TCHOUATCHEU GAETAN BRUNEL**  
*Ing√©nieur Logiciel & Data | √âtudiant ESIEA*

üìß Email : gaetanbrunel.kamenitchouatcheu@et.esiea.fr  
üêô GitHub : @Lkb-2905  

¬© 2026 Kameni Tchouatcheu Gaetan Brunel - Tous droits r√©serv√©s
